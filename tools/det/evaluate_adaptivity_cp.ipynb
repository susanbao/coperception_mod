{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14dc7ddc-3a49-4353-bba8-b06fe623757c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluating Adaptivity for Conformal Prediction\n",
    "\n",
    "Size-stratified coverage metric\n",
    "\n",
    "Divide the observations into several groups depending on the size of prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ab5be3-78df-463c-a815-4f7d957de64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde3c5-652c-4a8f-9194-8eda98c5931f",
   "metadata": {},
   "source": [
    "## for kl_loss_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4a150bc-1115-4d35-b8fe-d32696d05bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(data_path):\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "    tp = data.item()['tp']\n",
    "    scores = []\n",
    "    for i in range(len(tp)):\n",
    "        prediction = np.array(tp[i][0])\n",
    "        pred = prediction[:,:8]\n",
    "        target = np.array(tp[i][1])\n",
    "        cov = prediction[:,9:]\n",
    "        score = np.abs(pred-target) / np.sqrt(np.exp(cov))\n",
    "        for s in score:\n",
    "            scores.append(list(s))\n",
    "    return np.array(scores)\n",
    "\n",
    "def compute_quantile(scores, alpha):\n",
    "    n = scores.shape[0]\n",
    "    q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "    quantile = []\n",
    "    for i in range(scores.shape[1]):\n",
    "        q = np.quantile(scores[:,i], q_level, interpolation='higher')\n",
    "        quantile.append(q)\n",
    "    return quantile\n",
    "\n",
    "def get_range(data_path):\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "    tp = data.item()['tp']\n",
    "    sizes = []\n",
    "    for i in range(len(tp)):\n",
    "        prediction = np.array(tp[i][0])\n",
    "        cov = prediction[:,9:]\n",
    "        cov = np.sqrt(np.exp(cov))\n",
    "        for c in cov:\n",
    "            sizes.append(list(c))\n",
    "    sizes = np.array(sizes) * 2\n",
    "    print(\"max: {}\".format(np.max(sizes, axis=0)))\n",
    "    print(\"min: {}\".format(np.min(sizes, axis=0)))\n",
    "    sum_sizes = np.sum(sizes, axis=1)\n",
    "    print(sum_sizes.shape)\n",
    "    print(np.max(sum_sizes), np.min(sum_sizes))\n",
    "    return\n",
    "\n",
    "def divide_group_corner(data_path, num_group=10):\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "    tp = data.item()['tp']\n",
    "    sizes = []\n",
    "    for i in range(len(tp)):\n",
    "        prediction = np.array(tp[i][0])\n",
    "        cov = prediction[:,9:]\n",
    "        cov = np.sqrt(np.exp(cov))\n",
    "        for c in cov:\n",
    "            sizes.append(list(c))\n",
    "    sizes = np.array(sizes) * 2\n",
    "    sum_sizes = np.sum(sizes, axis=1)\n",
    "    sum_sizes.sort()\n",
    "    sum_sizes = sum_sizes\n",
    "    divides = [0]\n",
    "    num_in_each_group = sum_sizes.shape[0] // num_group\n",
    "    for index, v in enumerate(sum_sizes):\n",
    "        if (index != 0) and (index % num_in_each_group == 0):\n",
    "            divides.append(v)\n",
    "    groups = []\n",
    "    for i in range(num_group - 1):\n",
    "        groups.append(np.logical_and(divides[i] < sum_sizes, sum_sizes  <= divides[i+1]))\n",
    "    groups.append(sum_sizes > divides[num_group-1])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40245004-1cbc-49f6-b481-d2756845b828",
   "metadata": {},
   "source": [
    "### disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0df8ee00-12f8-4049-9b3b-58e85258eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size : (32881,)\n",
      "0 0.08612249213197869\n",
      "0.08612249213197869 0.2010650212460241\n",
      "0.2010650212460241 0.2399124569523825\n",
      "0.2399124569523825 0.2777768722642634\n",
      "0.2777768722642634 0.32539610887189485\n",
      "0.32539610887189485 0.37689525129267276\n",
      "0.37689525129267276 0.4401605506880663\n",
      "0.4401605506880663 0.5183131784311394\n",
      "0.5183131784311394 0.6529042129644977\n",
      "0.6529042129644977\n"
     ]
    }
   ],
   "source": [
    "data_path = \"check/check_loss_two_step_corner/disco/no_rsu/match_all_data_100_5.npy\"\n",
    "groups = divide_group_corner(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fed2b991-2698-4af0-8295-3ddb38dfb2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3289., 3288., 3288., 3288., 3288., 3288., 3288., 3288., 3288.,\n",
       "       3288.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(groups).astype(float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabfb0a-032a-44ab-b34f-4b5fe314888a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
